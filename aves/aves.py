# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eL9KzUnS2OqDjGWzZ_MLDC6oyR9jEeJC
"""

import os
import subprocess
from PIL import Image
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.losses import CategoricalCrossentropy

TRAIN_DIRECTORY = "/LUSTRE/home/rn_lcc_11/share/birds/train"
TEST_DIRECTORY = "/LUSTRE/home/rn_lcc_11/share/birds/test"

datos = []

for nombre_ave in os.listdir(TRAIN_DIRECTORY):
    ruta_ave = os.path.join(TRAIN_DIRECTORY, nombre_ave)

    if os.path.isdir(ruta_ave):
        for archivo in os.listdir(ruta_ave):
            ruta_imagen = os.path.join(ruta_ave, archivo)
            if os.path.isfile(ruta_imagen):
                datos.append({
                    "ruta": ruta_imagen,
                    "etiqueta": nombre_ave
                })

df = pd.DataFrame(datos)
print(df.head())

df_train, df_val = train_test_split(df, test_size=0.2, stratify=df['etiqueta'], random_state=42)

# Generador de entrenamiento con aumentos y preprocesamiento para MobileNetV2
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,  # Aplica el preprocesamiento de MobileNetV2
    rotation_range=20,           # Rota hasta 20 grados
    width_shift_range=0.1,       # Desplazamiento horizontal
    height_shift_range=0.1,      # Desplazamiento vertical
    shear_range=0.1,             # Cizalla
    brightness_range=[0.8, 1.2], # Brillo
    zoom_range=0.3,              # Zoom aleatorio
    horizontal_flip=True,        # Volteo horizontal
    vertical_flip=True,          # Volteo vertical
    fill_mode='nearest'          # Cómo rellenar los pixeles vacíos
)

# Generador de validación con preprocesamiento para MobileNetV2
val_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input  # Aplica el preprocesamiento de MobileNetV2
)

train_generator = train_datagen.flow_from_dataframe(
    dataframe=df_train,
    x_col='ruta',
    y_col='etiqueta',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=True
)

# Generador de validación
val_generator = val_datagen.flow_from_dataframe(
    dataframe=df_val,
    x_col='ruta',
    y_col='etiqueta',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False  # Mejor no barajar la validación
)

# Cargamos MobileNetV2 sin la parte final (top), con pesos preentrenados en ImageNet
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Congelamos la base para entrenar solo las capas nuevas primero
base_model.trainable = False

train_generator.classes
num_clases = len(train_generator.class_indices)

# Añadimos nuestras capas encima de la base
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dropout(0.3)(x)
outputs = Dense(num_clases)(x)

model = Model(inputs=base_model.input, outputs=outputs)

model.compile(
    optimizer=Adam(learning_rate=1e-3),
    loss=CategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)

model.summary()

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

callbacks = [
    EarlyStopping(patience=5, restore_best_weights=True),
    ReduceLROnPlateau(factor=0.2, patience=3, verbose=1),
]

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=20,  # Ajusta según lo que necesites
    callbacks=callbacks
)

import matplotlib.pyplot as plt

# Precisión
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Entrenamiento')
plt.plot(history.history['val_accuracy'], label='Validación')
plt.title('Precisión (Accuracy)')
plt.xlabel('Épocas')
plt.ylabel('Precisión')
plt.legend()

# Pérdida
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Entrenamiento')
plt.plot(history.history['val_loss'], label='Validación')
plt.title('Pérdida (Loss)')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.legend()

plt.tight_layout()
plt.savefig("Accuracy_y_Loss1.png")
plt.close()

base_model.trainable = True

model.compile(
    optimizer=Adam(learning_rate=1e-5),  # más pequeño para fine-tuning
    loss=CategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)

history_finetune = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=20,  # Puedes ajustar según los resultados
    callbacks=callbacks  # Los mismos que antes: EarlyStopping, etc.
)

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history_finetune.history['accuracy'], label='Entrenamiento')
plt.plot(history_finetune.history['val_accuracy'], label='Validación')
plt.title('Precisión (Accuracy)')
plt.xlabel('Épocas')
plt.ylabel('Precisión')
plt.legend()

# Pérdida
plt.subplot(1, 2, 2)
plt.plot(history_finetune.history['loss'], label='Entrenamiento')
plt.plot(history_finetune.history['val_loss'], label='Validación')
plt.title('Pérdida (Loss)')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.legend()

plt.tight_layout()
plt.savefig("Accuracy_y_Loss2.png")
plt.close()

test = []

for nombre_ave in os.listdir(TEST_DIRECTORY):
    ruta_ave = os.path.join(TEST_DIRECTORY, nombre_ave)

    if os.path.isdir(ruta_ave):
        for archivo in os.listdir(ruta_ave):
            ruta_imagen = os.path.join(ruta_ave, archivo)
            if os.path.isfile(ruta_imagen):
                test.append({
                    "ruta": ruta_imagen,
                    "etiqueta": nombre_ave
                })

df1 = pd.DataFrame(datos)
print(df1.head())

test_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input  # Aplica el preprocesamiento de MobileNetV2
)

test_generator = test_datagen.flow_from_dataframe(
    dataframe=df1,
    x_col='ruta',
    y_col='etiqueta',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

# Predicciones del modelo
preds = model.predict(test_generator, verbose=1)

# Convertimos a clases predichas
y_pred = np.argmax(preds, axis=1)

# Clases reales
y_true = test_generator.classes

from sklearn.metrics import classification_report, confusion_matrix

# Mapeo de índices a nombres de clases
class_labels = list(test_generator.class_indices.keys())

# Reporte de desempeño
print(classification_report(y_true, y_pred, target_names=class_labels))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, cmap="Blues")
plt.title("Matriz de Confusión")
plt.xlabel("Predicción")
plt.ylabel("Real")
plt.savefig("Confusion.png")
plt.close()

model.save("modelo.h5")
