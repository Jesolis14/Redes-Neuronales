# -*- coding: utf-8 -*-
"""Copia de Bag classes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16xzdSjFbAjE7jWZceqbzDGLyVqfu5hlj

#Clasificación de bolsas

[Kaggle dataset](https://www.kaggle.com/datasets/vencerlanz09/plastic-paper-garbage-bag-synthetic-images)

* Usar CNN
* Espero al menos un 80% de accuracy
"""

import time
tiempo_inicial = time.time()

import datetime
import zoneinfo

# creamos las zonas horarias ( https://nodatime.org/TimeZones )
zona_hermosillo = zoneinfo.ZoneInfo("America/Hermosillo")

# Common
import cv2
import os
import keras
import numpy as np
from glob import glob
from tqdm import tqdm
import tensorflow as tf
import matplotlib.pyplot as plt

# Data processing
import pandas as pd
#from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Data visuals
import seaborn as sns
import matplotlib.pyplot as plt

# Model build
from keras import Sequential
#from keras.layers import Dense, Dropout
from keras.models import load_model
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Callbacks
from keras.callbacks import EarlyStopping, ModelCheckpoint

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt




"""## Cargar los datos"""

data_dir = '/LUSTRE/home/rn_lcc_11/share/BagClasses/BagClasses'

img_height = 150
img_width  = 150
batch_size = 32

train_ds, test_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split = 0.2,
  subset           = "both",
  seed             = 123,
  image_size       = (img_height, img_width),
  batch_size       = batch_size)

class_names = train_ds.class_names

"""# **Visualizando las imágenes y las clases**"""

'''
plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")
'''

datos_entrenamiento = []

for i, (imagenes, etiquetas) in enumerate(train_ds):
    imagenes_np = imagenes.numpy()
    etiquetas_np = etiquetas.numpy()

    for j in range(imagenes_np.shape[0]):
        img = imagenes_np[j]
        # Convertir de RGB a BGR
        img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
        # Asegurarse de que tenga la forma (img_height, img_width, 3)
        img_bgr = img_bgr.reshape(img_height, img_width, 3)
        datos_entrenamiento.append([img_bgr, etiquetas_np[j]])

X = []
y=  []

for imagen, etiqueta in datos_entrenamiento:
  X.append(imagen)
  y.append(etiqueta)

X = np.array(X).astype(float) / 255

y = np.array(y)

datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=15,
    zoom_range=[0.7, 1.4],
    horizontal_flip=True,
    vertical_flip=True
)

datagen.fit(X)

X_entrenamiento = X[:9400]
X_validacion = X[9400:]
y_entrenamiento = y[:9400]
y_validacion = y[9400:]

data_gen_entrenamiento = datagen.flow(X_entrenamiento, y_entrenamiento, batch_size=32)

modelo = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),

  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(100, activation='relu'),
  tf.keras.layers.Dense(3, activation='softmax')
])

modelo.compile(optimizer='adam',
               loss='sparse_categorical_crossentropy',
               metrics=['accuracy'])

def plot_hist(hist):
    history = hist.history
    plt.plot(history["accuracy"], label="Entrenamiento")
    plt.plot(history["val_accuracy"], label="Validación")
    plt.title("Precisión del modelo (Accuracy)")
    plt.ylabel("Precisión")
    plt.xlabel("Época")
    plt.ylim((0, 1.1))
    plt.legend(loc="lower right")
    plt.grid()
    plt.savefig("accuracy.png")
    plt.close()
    plt.plot(history["loss"], 'r', label="Entrenamiento")
    plt.plot(history["val_loss"], 'b', label="Validación")
    plt.title("Pérdida del modelo (Loss)")
    plt.ylabel("Pérdida")
    plt.xlabel("Época")
    plt.legend(loc="upper right")
    plt.grid()
    plt.savefig("loss.png")
    plt.close()

import gc
gc.collect()

historial = modelo.fit(
    data_gen_entrenamiento,
    epochs=80, batch_size=32,
    validation_data=(X_validacion, y_validacion),
    steps_per_epoch=int(np.ceil(len(X_entrenamiento) / float(32))),
    validation_steps=int(np.ceil(len(X_validacion) / float(32)))
)

plot_hist(historial)

y_true = []
y_test = []

for i, (imagenes, etiquetas) in enumerate(test_ds):
    # Convertir el batch a arrays de NumPy
    imagenes_np = imagenes.numpy()
    etiquetas_np = etiquetas.numpy()

    # Iterar sobre cada imagen en el batch
    for j in range(imagenes_np.shape[0]):
        img = imagenes_np[j]
        # Convertir la imagen a escala de grises
        mg_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
        # Reestructurar la imagen para agregar la dimensión del canal
        img_gray = img_gray.reshape(img_height, img_width, 3)
        y_test.append(img_gray)
        y_true.append(etiquetas_np[j])

# Convertir a arrays de NumPy
y_true = np.array(y_true)
y_test = np.array(y_test)

y_true

y_pred_labels

y_pred = modelo.predict(y_test)

y_pred

from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# Convertir y_pred a etiquetas discretas (si es one-hot o probabilidades)
y_pred_labels = np.argmax(y_pred, axis=1)

# Ahora calculamos la matriz de confusión con las etiquetas discretas
cm = confusion_matrix(y_true, y_pred_labels)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d",
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel("Clase Predicha")
plt.ylabel("Clase Verdadera")
plt.title("Matriz de Confusión")
plt.savefig("Matriz_de_Confusión.png")
plt.close()